{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c7f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "2107\n",
      "2131\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "%run 'model.ipynb'\n",
    "\n",
    "train_data = pd.read_pickle('train_data.pkl')\n",
    "val_data = pd.read_pickle('val_data.pkl')\n",
    "\n",
    "#initialize the encoder\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE).to(device)\n",
    "\n",
    "# Initialize the attention layer\n",
    "attention_layer = BahdanauAttention(units)\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE).to(device)\n",
    "\n",
    "#getting the model weights \n",
    "encoder.load_state_dict(torch.load('encoder.pth', map_location=device))\n",
    "decoder.load_state_dict(torch.load('decoder.pth', map_location=device))\n",
    "\n",
    "max_length_targ = max(len(t.split()) for t in train_data['answer'])\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = clean_text(sentence)\n",
    "\n",
    "    inputs = [src_vocab[token] for token in sentence.split(' ')]\n",
    "    inputs = torch.tensor([inputs]).to(device)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    # Initialize the hidden state with zeros\n",
    "    hidden = torch.zeros((1, 1, units)).to(device)  # Modify the shape according to  GRU layer if changes \n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = torch.tensor([[tgt_vocab['<sos>']]], dtype=torch.long).to(device)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        predicted_id = torch.argmax(predictions[0]).item()\n",
    "\n",
    "        # Reverse lookup function\n",
    "        def index_to_word(vocab, index):\n",
    "            return vocab.get_itos()[index]\n",
    "\n",
    "        if index_to_word(tgt_vocab, predicted_id) == '<eos>':\n",
    "            break\n",
    "\n",
    "        result += index_to_word(tgt_vocab, predicted_id) + ' '\n",
    "\n",
    "        # The predicted ID is fed back into the model\n",
    "        dec_input = torch.tensor([[predicted_id]], dtype=torch.long).to(device)\n",
    "\n",
    "    return result, sentence\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def ask(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    print('Question: %s' % (sentence))\n",
    "    print('Predicted answer: {}'.format(result))\n",
    "\n",
    "# Load questions and answers from a file\n",
    "questions = []\n",
    "answers = []\n",
    "with open(\"./dialogs.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.split('\\t')\n",
    "        questions.append(line[0])\n",
    "        answers.append(line[1])\n",
    "\n",
    "print(len(questions) == len(answers))\n",
    "\n",
    "# Preprocessing functions\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = unicode_to_ascii(text.lower().strip())\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"\\r\", \"\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
    "    text = re.sub(\"(\\\\W)\",\" \",text) \n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text)\n",
    "    text =  \"<sos> \" +  text + \" <eos>\"\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c65921bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: <sos> i have actually been pretty good you <eos>\n",
      "Predicted answer: <sos> i am actually in school right now \n",
      "None\n",
      "i'm actually in school right now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage with a specific question\n",
    "print(ask(questions[15]))\n",
    "print(answers[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee6a9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your question (or 'exit' to quit): Hi,can you help me?\n",
      "Model's answer: ('<sos> what ', '<sos> hican you help me <eos>')\n",
      "\n",
      "\n",
      "Type your question (or 'exit' to quit): hello\n",
      "Model's answer: ('<sos> no one knows is there a lot of money ', '<sos> hello <eos>')\n",
      "\n",
      "\n",
      "Type your question (or 'exit' to quit): Hi, there are a lot of people here.\n",
      "Model's answer: ('<sos> you are right ', '<sos> hi there are a lot of people here <eos>')\n",
      "\n",
      "\n",
      "Type your question (or 'exit' to quit): Hello, how are you?\n",
      "Model's answer: ('<sos> i am fine how about yourself ', '<sos> hello how are you <eos>')\n",
      "\n",
      "\n",
      "Type your question (or 'exit' to quit): exit\n"
     ]
    }
   ],
   "source": [
    "# Function to interactively ask questions and get answers\n",
    "def interact_with_model():\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"Type your question (or 'exit' to quit): \")\n",
    "\n",
    "        # Check if the user wants to exit\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        # Get the model's answer\n",
    "        answer = evaluate(user_input)\n",
    "\n",
    "        # Display the model's answer\n",
    "        print(\"Model's answer:\", answer)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Start the interactive loop\n",
    "interact_with_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ebc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
